{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Analysis\n",
    "\n",
    "## Goal: Create a model to find similar users based on each user's review text.\n",
    "\n",
    "\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import statsmodels.formula.api as sm\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "import gzip\n",
    "from pandas import Series\n",
    "from six.moves.html_parser import HTMLParser\n",
    "from scipy import spatial\n",
    "import heapq\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text analysis - Class to get Similarity from Text Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TextSimilarity:\n",
    "    def __init__(self, path): #user_rand_sample_1000.csv\n",
    "        \"Assigns data to data_df property\"\n",
    "        data_df = pd.read_csv(path)\n",
    "        years = []\n",
    "        months = []\n",
    "        days = []\n",
    "        for date in data_df['reviewTime']:\n",
    "            splitted = date.split(' ')\n",
    "            years.append(splitted[2])\n",
    "            months.append(splitted[0])\n",
    "            day = splitted[1]\n",
    "            days.append(day[:-1])\n",
    "        date_df = pd.DataFrame({'year': years,\n",
    "                               'month': months,\n",
    "                               'day': days})\n",
    "        final_dates = pd.to_datetime(date_df)\n",
    "        data_df['datetimes'] = final_dates\n",
    "        print \"Shape of our dataset: \", data_df.shape\n",
    "        print \"Number of unique users in the dataset: \",len(np.unique(data_df['reviewerID'].values))\n",
    "        self.data_df = data_df\n",
    "        \n",
    "    def groupByUser(self):\n",
    "        \"Creates a new property data_combined that groups the dataframe by user\"\n",
    "        print \"Grouping data by user....\"\n",
    "        data_sample = self.data_df[['reviewText','reviewerID','overall']]\n",
    "        co2 = self._percentage_coroutine(len(data_sample.groupby('reviewerID')))\n",
    "        co2.next()\n",
    "        data_combined = data_sample.groupby('reviewerID').apply(self._trace_progress(self._groupByUser,progress=co2))\n",
    "        h = HTMLParser()\n",
    "        remove_html = lambda x: h.unescape(x)\n",
    "        data_combined['reviewText'] = data_combined['reviewText'].map(remove_html)\n",
    "        self.data_combined = data_combined\n",
    "        \n",
    "    def countWords(self):\n",
    "        \"Applies a count vectorizer and stores result to vectorized\"\n",
    "        vectorizer = CountVectorizer(stop_words = 'english',min_df=4, decode_error=\"replace\")\n",
    "        reviews = self.data_combined['reviewText'].values\n",
    "        x = vectorizer.fit_transform(reviews)\n",
    "        self.vectorized = x.toarray()\n",
    "        self.all_feature_names = vectorizer.get_feature_names() \n",
    "        print len(self.all_feature_names), \" unique words found in reviews\"\n",
    "        \n",
    "    def calculateScores(self):\n",
    "        \"Calculates the TF-IDF based on the vectorized data\"\n",
    "        # Get IDF \n",
    "        document_frequency = np.sum(self.vectorized,axis=0)\n",
    "        print \"Calculated Document frequency\"\n",
    "        idf_raw = np.divide(float(self.vectorized.shape[0]),document_frequency)\n",
    "        idf = np.log10(idf_raw)\n",
    "        print \"Calculated IDF\"\n",
    "        tf = 1 + np.log10(self.vectorized)\n",
    "        tf[tf<0]=0\n",
    "        self.tf_idf = np.multiply(tf,idf)\n",
    "\n",
    "\n",
    "    def _groupByUser(self,x):\n",
    "        return pd.Series(dict(reviewText = \"%s\" % ''.join(str(x['reviewText'].values))))\n",
    "    \n",
    "    def _trace_progress(self, func, progress = None):\n",
    "        def callf(*args, **kwargs):\n",
    "            if (progress is not None):\n",
    "                progress.send(None)\n",
    "\n",
    "            return func(*args, **kwargs)\n",
    "\n",
    "        return callf\n",
    "    \n",
    "    def _percentage_coroutine(self, to_process, print_on_percent = 0.25):\n",
    "        print \"Starting progress percentage monitor\"\n",
    "        processed = 0\n",
    "        count = 0\n",
    "        print_count = to_process*print_on_percent\n",
    "        while True:\n",
    "            yield\n",
    "            processed += 1\n",
    "            count += 1\n",
    "            if (count >= print_count):\n",
    "                count = 0\n",
    "                pct = (float(processed)/float(to_process))*100\n",
    "                print \"{}% finished\".format(pct)\n",
    "                \n",
    "    def _getCosineMatrix(self):\n",
    "        tf_idf = self.tf_idf\n",
    "        cosine_sim_results = np.zeros((tf_idf.shape[0],tf_idf.shape[0]))\n",
    "        for user1 in range(tf_idf.shape[0]):\n",
    "            for user2 in range(tf_idf.shape[0]):\n",
    "                cosine_sim_results[user1,user2] = spatial.distance.cosine(tf_idf[user1],tf_idf[user2])\n",
    "            if user1%20==0: \n",
    "                print \"Completed \",user1, \" users\"\n",
    "                #print float(user1)/tf_idf.shape[0], cosine_sim_results[user1,user2]\n",
    "        \n",
    "        self.cosine_sim_results = cosine_sim_results\n",
    "        \n",
    "    def getCosineMatrix(self):\n",
    "        \"Returns a matrix of cosine similarity that is N-users by N-users\"\n",
    "        tf_idf = self.tf_idf\n",
    "        magnitude =  np.linalg.norm(tf_idf, axis=1)\n",
    "        tf_idf_norm = tf_idf/magnitude[:,None]\n",
    "        self.cosine_sim_results = tf_idf_norm.dot(tf_idf_norm.T)\n",
    "        return self.cosine_sim_results                            \n",
    "                \n",
    "    def getSimilarityMatrix(self):\n",
    "        \"Returns sorted array of most similar users for each user\"\n",
    "        neighbors = np.zeros((self.cosine_sim_results.shape[0],10))\n",
    "        count=0\n",
    "        for row in self.cosine_sim_results:\n",
    "            # get the indices that would sort the row\n",
    "            # replace values with the index\n",
    "            # sort the rows\n",
    "            closest10 = heapq.nsmallest(10, range(len(row)), row.take)\n",
    "            neighbors[count] = closest10\n",
    "            count+=1\n",
    "        self.neighbors = neighbors\n",
    "        print \"Calculated Similarity Matrix\"\n",
    "        return self.neighbors\n",
    "    \n",
    "    def fit(self):\n",
    "        \"Perform all calculations\"\n",
    "        self.groupByUser()\n",
    "        self.countWords()\n",
    "        self.calculateScores()\n",
    "        text_cosine_matrix = self.getCosineMatrix()\n",
    "        self.getSimilarityMatrix()\n",
    "        \n",
    "    def searchReviews(self,search_term): \n",
    "        index = self.all_feature_names.index(search_term)\n",
    "        first_user_with_term = np.argmax(self.vectorized[:,index]>0)\n",
    "        self.printNeighbors(first_user_with_term)\n",
    "        #print(\"We haven't calculated that one yet\")\n",
    "            \n",
    "    def printNeighbors(self,user):\n",
    "        for each in self.neighbors[user,0:6]:\n",
    "            print \"\\nUser: \", each, \"Cosine: \", self.cosine_sim_results[user,each]\n",
    "            print self.data_combined['reviewText'][int(each)]\n",
    "            print \"--------\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of our dataset:  (12471, 12)\n",
      "Number of unique users in the dataset:  1000\n",
      "Grouping data by user....\n",
      "Starting progress percentage monitor\n",
      "25.0% finished\n",
      "50.0% finished\n",
      "75.0% finished\n",
      "100.0% finished\n",
      "9401  unique words found in reviews\n",
      "Calculated Document frequency\n",
      "Calculated IDF\n",
      "Calculated Similarity Matrix\n"
     ]
    }
   ],
   "source": [
    "textSimilarity = TextSimilarity('user_rand_sample_1000.csv')\n",
    "textSimilarity.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.20449872,  0.17545035, ...,  0.17896626,\n",
       "         0.09904113,  0.0926708 ],\n",
       "       [ 0.20449872,  1.        ,  0.25197203, ...,  0.21635667,\n",
       "         0.09100937,  0.10615786],\n",
       "       [ 0.17545035,  0.25197203,  1.        , ...,  0.20284616,\n",
       "         0.075706  ,  0.08639352],\n",
       "       ..., \n",
       "       [ 0.17896626,  0.21635667,  0.20284616, ...,  1.        ,\n",
       "         0.10148614,  0.06044012],\n",
       "       [ 0.09904113,  0.09100937,  0.075706  , ...,  0.10148614,\n",
       "         1.        ,  0.0481088 ],\n",
       "       [ 0.0926708 ,  0.10615786,  0.08639352, ...,  0.06044012,\n",
       "         0.0481088 ,  1.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get cosine similarity matrix \n",
    "textSimilarity.cosine_sim_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 512.,  309.,  450., ...,  617.,  994.,  991.],\n",
       "       [ 512.,  788.,  309., ...,  245.,  941.,  991.],\n",
       "       [ 512.,  788.,  861., ...,  309.,  617.,  245.],\n",
       "       ..., \n",
       "       [ 512.,  309.,  861., ...,  110.,  245.,  450.],\n",
       "       [ 512.,  450.,   46., ...,  552.,  472.,  406.],\n",
       "       [ 512.,  763.,  919., ...,  758.,  299.,   46.]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get similarity matrix (for each user, shows sorted list of most similar users)\n",
    "textSimilarity.neighbors"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
