{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Ratings\n",
    "\n",
    "## Text Analysis, User-based Collaborative Filtering, and Simple Averaging\n",
    "\n",
    "\n",
    "\n",
    "-----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import statsmodels.formula.api as sm\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.linear_model import LogisticRegression as LogReg\n",
    "from sklearn.decomposition import PCA\n",
    "import json\n",
    "import gzip\n",
    "from pandas import Series\n",
    "from six.moves.html_parser import HTMLParser\n",
    "from scipy import spatial\n",
    "import heapq\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text analysis - Class to get Similarity from Text Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class TextSimilarity:\n",
    "    def __init__(self, data_df): #user_rand_sample_1000.csv\n",
    "        \"Assigns data to data_df property\"\n",
    "        #data_df = pd.read_csv(path)\n",
    "        print \"Shape of our dataset: \", data_df.shape\n",
    "        print \"Number of unique users in the dataset: \",len(np.unique(data_df['reviewerID'].values))\n",
    "        self.data_df = data_df\n",
    "        \n",
    "    def groupByUser(self):\n",
    "        \"Creates a new property data_combined that groups the dataframe by user\"\n",
    "        print \"Grouping data by user....\"\n",
    "        data_sample = self.data_df[['reviewText','reviewerID','overall']]\n",
    "        co2 = self._percentage_coroutine(len(data_sample.groupby('reviewerID')))\n",
    "        co2.next()\n",
    "        data_combined = data_sample.groupby('reviewerID').apply(self._trace_progress(self._groupByUser,progress=co2))\n",
    "        h = HTMLParser()\n",
    "        remove_html = lambda x: h.unescape(x)\n",
    "        data_combined['reviewText'] = data_combined['reviewText'].map(remove_html)\n",
    "        self.data_combined = data_combined\n",
    "        \n",
    "    def countWords(self):\n",
    "        \"Applies a count vectorizer and stores result to vectorized\"\n",
    "        vectorizer = CountVectorizer(stop_words = 'english',min_df=4, decode_error=\"replace\")\n",
    "        reviews = self.data_combined['reviewText'].values\n",
    "        x = vectorizer.fit_transform(reviews)\n",
    "        self.vectorized = x.toarray()\n",
    "        self.all_feature_names = vectorizer.get_feature_names() \n",
    "        print len(self.all_feature_names), \" unique words found in reviews\"\n",
    "        \n",
    "    def calculateScores(self):\n",
    "        \"Calculates the TF-IDF based on the vectorized data\"\n",
    "        # Get IDF \n",
    "        document_frequency = np.sum(self.vectorized,axis=0)\n",
    "        print \"Calculated Document frequency\"\n",
    "        idf_raw = np.divide(float(self.vectorized.shape[0]),document_frequency)\n",
    "        idf = np.log10(idf_raw)\n",
    "        print \"Calculated IDF\"\n",
    "        tf = 1 + np.log10(self.vectorized)\n",
    "        tf[tf<0]=0\n",
    "        self.tf_idf = np.multiply(tf,idf)\n",
    "\n",
    "\n",
    "    def _groupByUser(self,x):\n",
    "        return pd.Series(dict(reviewText = \"%s\" % ''.join(str(x['reviewText'].values))))\n",
    "    \n",
    "    def _trace_progress(self, func, progress = None):\n",
    "        def callf(*args, **kwargs):\n",
    "            if (progress is not None):\n",
    "                progress.send(None)\n",
    "\n",
    "            return func(*args, **kwargs)\n",
    "\n",
    "        return callf\n",
    "    \n",
    "    def _percentage_coroutine(self, to_process, print_on_percent = 0.25):\n",
    "        print \"Starting progress percentage monitor\"\n",
    "        processed = 0\n",
    "        count = 0\n",
    "        print_count = to_process*print_on_percent\n",
    "        while True:\n",
    "            yield\n",
    "            processed += 1\n",
    "            count += 1\n",
    "            if (count >= print_count):\n",
    "                count = 0\n",
    "                pct = (float(processed)/float(to_process))*100\n",
    "                print \"{}% finished\".format(pct)\n",
    "                \n",
    "    def _getCosineMatrix(self):\n",
    "        tf_idf = self.tf_idf\n",
    "        cosine_sim_results = np.zeros((tf_idf.shape[0],tf_idf.shape[0]))\n",
    "        for user1 in range(tf_idf.shape[0]):\n",
    "            for user2 in range(tf_idf.shape[0]):\n",
    "                cosine_sim_results[user1,user2] = spatial.distance.cosine(tf_idf[user1],tf_idf[user2])\n",
    "            if user1%20==0: \n",
    "                print \"Completed \",user1, \" users\"\n",
    "                #print float(user1)/tf_idf.shape[0], cosine_sim_results[user1,user2]\n",
    "        \n",
    "        self.cosine_sim_results = cosine_sim_results\n",
    "        \n",
    "    def getCosineMatrix(self):\n",
    "        \"Returns a matrix of cosine similarity that is N-users by N-users\"\n",
    "        tf_idf = self.tf_idf\n",
    "        magnitude =  np.linalg.norm(tf_idf, axis=1)\n",
    "        tf_idf_norm = tf_idf/magnitude[:,None]\n",
    "        self.cosine_sim_results = tf_idf_norm.dot(tf_idf_norm.T)\n",
    "        return self.cosine_sim_results                            \n",
    "                \n",
    "    def getSimilarityMatrix(self):\n",
    "        \"Returns sorted array of most similar users for each user\"\n",
    "        neighbors = np.zeros((self.cosine_sim_results.shape[0],10))\n",
    "        count=0\n",
    "        for row in self.cosine_sim_results[:1000]:\n",
    "            # get the indices that would sort the row\n",
    "            # replace values with the index\n",
    "            # sort the rows\n",
    "            closest10 = heapq.nlargest(10, range(len(row)), row.take)\n",
    "            neighbors[count] = closest10\n",
    "            count+=1\n",
    "            if count%100==0: print count\n",
    "        self.neighbors = neighbors\n",
    "        print \"Calculated Similarity Matrix\"\n",
    "        return self.neighbors\n",
    "    \n",
    "    def fit(self):\n",
    "        \"Perform all calculations\"\n",
    "        self.groupByUser()\n",
    "        self.countWords()\n",
    "        self.calculateScores()\n",
    "        text_cosine_matrix = self.getCosineMatrix()\n",
    "        self.getSimilarityMatrix()\n",
    "        \n",
    "    def searchReviews(self,search_term): \n",
    "        index = self.all_feature_names.index(search_term)\n",
    "        first_user_with_term = np.argmax(self.vectorized[:,index]>0)\n",
    "        self.printNeighbors(first_user_with_term)\n",
    "        #print(\"We haven't calculated that one yet\")\n",
    "            \n",
    "    def printNeighbors(self,user):\n",
    "        for each in self.neighbors[user,0:6]:\n",
    "            print \"\\nUser: \", each, \"Cosine: \", self.cosine_sim_results[user,each]\n",
    "            print self.data_combined['reviewText'][int(each)]\n",
    "            print \"--------\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data and split into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "data_df = pd.read_csv(\"frequent_reviews.txt\")\n",
    "data_sample = data_df[['reviewerID','overall','asin','reviewText']]\n",
    "msk = np.random.rand(len(data_sample)) < 0.3\n",
    "train = data_sample.copy()\n",
    "train['overall'][msk] = np.nan\n",
    "test = data_sample.copy()\n",
    "test['overall'][~msk] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the utility matrix (users vs ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "utility_matrix_train = train['overall'].groupby([train['reviewerID'], train['asin']]).mean().unstack()\n",
    "utility_matrix_test = test['overall'].groupby([test['reviewerID'], test['asin']]).mean().unstack()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(823, 996)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utility_matrix_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "utility_matrix_train_nan = utility_matrix_train\n",
    "utility_matrix_train = utility_matrix_train.fillna(value=0)\n",
    "utility_matrix_test_nan = utility_matrix_test\n",
    "utility_matrix_test = utility_matrix_test.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cosine similarity matrix using review text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14433, 4)\n",
      "Shape of our dataset:  (14433, 4)\n",
      "Number of unique users in the dataset:  823\n",
      "Grouping data by user....\n",
      "Starting progress percentage monitor\n",
      "25.0303766707% finished\n",
      "50.0607533414% finished\n",
      "75.0911300122% finished\n",
      "100.121506683% finished\n",
      "12071  unique words found in reviews\n",
      "Calculated Document frequency\n",
      "Calculated IDF\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "textSimilarity = TextSimilarity(train)\n",
    "textSimilarity.groupByUser()\n",
    "textSimilarity.countWords()\n",
    "textSimilarity.calculateScores()\n",
    "cosine_matrix_text = textSimilarity.getCosineMatrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "Calculated Similarity Matrix\n",
      "\n",
      "User:  20.0 Cosine:  1.0\n",
      "[ 'I liked very much. This was very well indeed. It was written well. Had a very well story line. Well!!!'\n",
      " \"This most definitely is a save to my faves. It's a reconnecting love story you have got to read again and again.\"\n",
      " 'This read was enjoyable, entertaining, romance. If you love romance get this story. It is one for the faves, ok.'\n",
      " 'I love to read about true love and this fits the bill. Most definitely worth two thumbs up and a save to faves.'\n",
      " \"That was very,very,very delightful. Two thumbs up and enjoyable experience. A good save to faves. I don't know what else to say.\"\n",
      " 'Even though it was short I liked this very much. I usually like it much more Spicer and a little more story. But it was very good.'\n",
      " 'Starting over and new beginnings. Thumbs up for Delilah and of course you know me by now. Another add to my faves.'\n",
      " \"Now that's a story. I enjoyed that so much that I will add it to my faves. Can't wait to read the full series.\"\n",
      " \"A very good surprise. I hope that there is more to the story. Because that only intrigued me to want to read more about Nisha and Drake's story.\"\n",
      " 'Kind of boring but ok! Why did you drag this on into another book. It could have been finished this book.'\n",
      " 'Aaahhhh love. Now that was a very good love story. And it was short but I enjoyed it very much.'\n",
      " \"I love a good love story. Especially when it's love at first glance. Well sort of any way thumbs up.\"]\n",
      "--------\n",
      "\n",
      "User:  371.0 Cosine:  0.460825877782\n",
      "[ 'This book was a wonderful read. I read until I finished it. Will most certainly read the next one. Get this book you will most certainly enjoy it.'\n",
      " 'This was a great read once I started to read it I found it hard to put down. I would say try it if you like these kinds of books you will enjoy it.'\n",
      " 'This was a really good book. I would recommend it . I would love to see what happens to the characters . It is also a young adult book but I enjoyed reading it. So get it and enjoy.'\n",
      " 'This is a wonderful good book. I have enjoyed reading it and hope to read more books by the same author. I want to find out what happens to the characters. So get it sit down and enjoy.'\n",
      " 'This was a good book. I enjoyed reading it it went a little slow in places but over all it was a good book. So if you like this kind of book go for it and enjoy.'\n",
      " 'This is a super good book I intend to read more of the series. I would recommend this book to anyone who wants to read this kind of book. It is a very good .'\n",
      " 'Get this book . I enjoyed reading this book. It kept going at a good pace did not slow down Will read the rest of them. So get the book and enjoy.'\n",
      " 'I give this 5 stars . It was a very good book I would be interested in the series. So get it and enjoy the book.'\n",
      " 'This is a good book but to short. I enjoyed reading it and would like to find out what happens to the characters. So get it and enjoy reading it.'\n",
      " 'This was a very good book. I enjoyed reading this book and will be getting the next one of the series. I would recommend this book. Get this book and enjoy it.'\n",
      " 'This was a really good book and I enjoyed it very much. I would recommend it to any of you who like to read this kind of book. So get it and enjoy reading it.'\n",
      " 'I very much enjoyed this book. The characters in this book were interesting and I will be getting the others.'\n",
      " 'This was a good book.I will be getting the others in the series. The characters in the book were really good.'\n",
      " 'This was a good book. I enjoyed reading the book. I would recommend this book to anyone who wants to read this kind of book.'\n",
      " 'This was a good book. I will be getting the others in this series. If you enjoy this type of book then I say get it and enjoy.'\n",
      " 'This is a super good book. But it needs to be longer. I look forward to reading the other books by this author. So I recommend this book to anyone who wants to read this kind of book. So get it and enjoy.'\n",
      " 'This was a good book and I enjoyed reading it very much. I would love to read more about the characters and find out what happens to them . So get it and read it. I hope you enjoy reading this book.'\n",
      " 'This was a really good book . I would recommend it to any one who wants to read this type of book. I would love to know what happens later on. So get it and enjoy.'\n",
      " 'This was a surprising good book. I enjoyed reading it very much. It kept me very interested the whole time nor was it slow at all. So if you like this kind of book then get it and enjoy reading.'\n",
      " \"Good book I would recommend it. There isn't a lot of action some romance but in all its a good short book. So get it and enjoy.\"\n",
      " 'This is a very good book. I would recommend it to any body who enjoys this kind of book. Go for it and enjoy reading.'\n",
      " 'This was a good book not what I have been reading lately. But I would recommend it to any body who enjoys this kind of book then get it. Get the book and enjoy.'\n",
      " 'This was a beautiful story. I enjoyed reading it very much. I would love to read more about the characters and what happens to them. So I recommend this book get it and enjoy it.']\n",
      "--------\n",
      "\n",
      "User:  269.0 Cosine:  0.440026554729\n",
      "[ \"He's in love with his best friend. His best friend is in love with can you do? You make plans to get together. A good book, for a weekend read.\"\n",
      " 'What a wonderful story. I fell in love with Trent, and Gage, also the children. The plot was great, and the characters was also good. A MUST READ. I enjoyed this book very much.'\n",
      " 'I enjoyed this book,it was well written, and the characters Braden, Wes, and Jesse was wonderful. I loved Jesse. The storyline was great. A wonderful romance. This is a good sequal in the BLACKCREEK series with COLLIDE being the first book.']\n",
      "--------\n",
      "\n",
      "User:  758.0 Cosine:  0.417938728108\n",
      "[ \"I love it it was great I'm glad I found your name a tried this book can't wait to read more from you\"\n",
      " \"I loved it can't wait to read more of this series keep up the good work and I will look forward to reading it.\"\n",
      " \"I like it a lot it was done just right try it you will like it.Can't wait for the next one in this series.\"]\n",
      "--------\n",
      "\n",
      "User:  390.0 Cosine:  0.409044104648\n",
      "[ 'This book was a GREAT book to read. I can read this book over again. I will look for more books from Cynthia.'\n",
      " 'This book is a very good reading book and I will look for more books like this book and read them too.'\n",
      " 'This book is a very good reading book and I will look for more books from the author and read books like this one.'\n",
      " 'This book is a very good reading book. The story line is good, I will look for more books from this author.'\n",
      " 'This book has a good story line in it. I really like the old time history in it, how they use to do it long ago. I will look for more books from this author and read them too.'\n",
      " 'This book is a very good reading book and I can read this book over again and over.I will look for more books from this series and read them too.'\n",
      " 'This book is a very good reading book and I can read this book over again and over.I will look for more books from this author and read them too.'\n",
      " \"I have read All three books now. I can't wait to read other books from Stacey. I am going to look for more books from Stacey.\"\n",
      " 'These books are good reading books. I will read them over and over. I will look for more books like them too.'\n",
      " 'This book is a good reading book.I will look for more books from this author. I like books like this one.'\n",
      " 'This book is a very good reading book and I will look for more books like this book. I can read this book over again and find more books from this author.'\n",
      " 'This book is a good reading book, it has a good story line in it. It has happy and sad in it.'\n",
      " 'This book is a very good reading book and I will read this book over again and over again, I will look for more books from this author and read them below.'\n",
      " 'This book is a very good reading book,I wish it was a longer book. The author is a very good writer and I have other books from this author too.'\n",
      " 'This book is a very good reading book. I like this kind of books, I like the past in books.'\n",
      " 'This six pack of books are good reading books. I can read these books again. I will look for more books from these authors.'\n",
      " 'This book is a very good reading reading book and I will look for more books from this author and read them too.']\n",
      "--------\n",
      "\n",
      "User:  661.0 Cosine:  0.407510371056\n",
      "[ 'I love this series of books.  I only gave it 4 starts because of the love-making scenes.  I think the stories could be just as awesome without them!!  But that has not stopped me from reading the series--I can just skip those scenes.'\n",
      " \"I'm trying to figure out what I want to write about this book.  It was really a good story about a young woman who becomes a mail order bride & mother who also finds out what being a true Christian means.  I like how she and George didn't just meet & instantly fell in love.  This is a clean romance that I would recommend to anyone who loves good, clean romance.\"\n",
      " 'What a wonderful storyline.  This was a great, clean book.  I definitely plan to read more by this wonderful author.'\n",
      " \"I loved the story very much.  I loved how everything worked out for everyone involved.  The story would have been just as good without the intimate details but that's just my feelings.\"]\n",
      "--------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:121: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "textSimilarity.getSimilarityMatrix()\n",
    "textSimilarity.printNeighbors(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get cosine similarity matrix using reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the cosine matrix for ratings\n",
    "# Normalize the utility matrix by dividing by the magnitude of each user vector\n",
    "magnitude =  np.linalg.norm(utility_matrix_train.values, axis=1)\n",
    "utility_matrix_norm = np.divide(utility_matrix_train.values,magnitude[:,None])\n",
    "utility_matrix_norm = np.nan_to_num(utility_matrix_norm) \n",
    "cosine_matrix_ratings = utility_matrix_norm.dot(utility_matrix_norm.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(cosine_matrix_ratings).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a version of the utility matrix that has subtracted each user's average rating\n",
    "values = utility_matrix_train.values\n",
    "means = np.true_divide(values.sum(1),(values!=0).sum(1))\n",
    "utility_matrix_rel_zero = (values-means[:,None])*(values!=0)\n",
    "utility_matrix_rel_zero = np.nan_to_num(utility_matrix_rel_zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get similarity matrix\n",
    "neighbors = np.zeros((cosine_matrix_ratings.shape[0],100))\n",
    "count = 0\n",
    "for row in cosine_matrix_ratings:\n",
    "# get the indices that would sort the row\n",
    "# replace values with the index and sort the rows\n",
    "    closest100 = heapq.nlargest(100, range(len(row)), row.take)\n",
    "    neighbors[count] = closest100\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  41.,  667.,  445.,  754.,  210.,  160.,  357.,  757.,   67.,\n",
       "          0.,    1.,    2.,    3.,    4.,    5.,    6.,    7.,    8.,\n",
       "          9.,   10.,   11.,   12.,   13.,   14.,   15.,   16.,   17.,\n",
       "         18.,   19.,   20.,   21.,   22.,   23.,   24.,   25.,   26.,\n",
       "         27.,   28.,   29.,   30.,   31.,   32.,   33.,   34.,   35.,\n",
       "         36.,   37.,   38.,   39.,   40.,   42.,   43.,   44.,   45.,\n",
       "         46.,   47.,   48.,   49.,   50.,   51.,   52.,   53.,   54.,\n",
       "         55.,   56.,   57.,   58.,   59.,   60.,   61.,   62.,   63.,\n",
       "         64.,   65.,   66.,   68.,   69.,   70.,   71.,   72.,   73.,\n",
       "         74.,   75.,   76.,   77.,   78.,   79.,   80.,   81.,   82.,\n",
       "         83.,   84.,   85.,   86.,   87.,   88.,   89.,   90.,   91.,   92.])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neighbors[41]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions using text similarity and ratings similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def predict(cosine_matrices):\n",
    "    predictions_all = []\n",
    "    start = time.clock()\n",
    "    n_users = utility_matrix_train.shape[0]\n",
    "    print \"start\"\n",
    "    publicRatings = utility_matrix_train_nan.mean().values\n",
    "    values = utility_matrix_train.values\n",
    "    means = np.true_divide(values.sum(1),(values!=0).sum(1))\n",
    "    utility_matrix_boolean = (utility_matrix_train.values>0).astype(int) # Get boolean version of train utility matrix\n",
    "    for cosine_matrix in cosine_matrices:\n",
    "        nohistory = 0\n",
    "        predictions = np.zeros(utility_matrix_train.shape)\n",
    "        for user in range(n_users):\n",
    "        #for user in range(10):\n",
    "            #print time.clock()-start\n",
    "            indices = utility_matrix_test.values[user]>0 # Books that were rated by the user in the test set\n",
    "            avgPublicRatings = utility_matrix_train_nan.ix[:,indices].mean().values # avg rating of the public for predict indices\n",
    "            avgPublicRatings[np.isnan(avgPublicRatings)] = avgPublicRatings[avgPublicRatings>0].mean() # impute missing values\n",
    "            avgPublicRatings[np.isnan(avgPublicRatings)] = utility_matrix_train_nan.mean().mean()\n",
    "            avgRating = means[user] # Avg rating for user across all books\n",
    "            if np.isnan(avgRating): # no user ratings available\n",
    "                predictions[user,indices] = avgPublicRatings\n",
    "                nohistory+=1\n",
    "                #print(user, \"no history\")\n",
    "                continue\n",
    "            myRatings = utility_matrix_rel_zero[user] # Actual Rating for user across all books\n",
    "            #print time.clock()-start\n",
    "\n",
    "            cosineTimesBooleanRatings = utility_matrix_boolean * cosine_matrix[user][:,None] # replace utility matrix ratings with cosine scores\n",
    "            cosineTimesBooleanRatings[user] = np.zeros((predictions.shape[1])) # remove user's row from neighbors calculation\n",
    "            cosineTimesBooleanRatings_norm =  cosineTimesBooleanRatings/cosineTimesBooleanRatings.sum(axis=0, keepdims=True) # normalize the matrix by dividing by the sum\n",
    "            cosineTimesBooleanRatings_norm = np.nan_to_num(cosineTimesBooleanRatings_norm) # get rid of nan values\n",
    "            cosineTimesRatings = utility_matrix_rel_zero * cosineTimesBooleanRatings_norm # element-wise multiplication\n",
    "            deltaFromNeighbors = np.sum(cosineTimesRatings[:,indices],axis=0)\n",
    "            noNeighborData = deltaFromNeighbors==0\n",
    "            # Make prediction\n",
    "            predictionsToMake = avgRating + 0.8*deltaFromNeighbors\n",
    "            predictionsToMake[noNeighborData] = 0.6*avgRating + 0.4*avgPublicRatings[noNeighborData]\n",
    "            predictionsToMake[predictionsToMake>5.0] = 5.0\n",
    "            predictions[user,indices] = predictionsToMake\n",
    "            #if np.isnan(predictions[user,:]).sum()>0: print user, \"NANS FOUND\"; break\n",
    "            if user%100==0: print user, \" users completed\"  \n",
    "            #print time.clock()-start\n",
    "        predictions_all.append(predictions)\n",
    "        print \"No user history: \", nohistory\n",
    "    final_predictions = sum(predictions_all)/float(len(predictions_all))\n",
    "    return predictions_all, final_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "0  users completed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py27/lib/python2.7/site-packages/numpy/core/_methods.py:59: RuntimeWarning: Mean of empty slice.\n",
      "  warnings.warn(\"Mean of empty slice.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  users completed\n",
      "300  users completed\n",
      "400  users completed\n",
      "500  users completed\n",
      "600  users completed\n",
      "700  users completed\n",
      "800  users completed\n",
      "No user history:  29\n",
      "0  users completed\n",
      "100  users completed\n",
      "300  users completed\n",
      "400  users completed\n",
      "500  users completed\n",
      "600  users completed\n",
      "700  users completed\n",
      "800  users completed\n",
      "No user history:  29\n"
     ]
    }
   ],
   "source": [
    "predictions_all, predictions = predict([cosine_matrix_text,cosine_matrix_ratings])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make predictions using simple averaging approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predictSimpleAvg():\n",
    "    predictions_simpleavg = np.zeros(utility_matrix_train.shape)\n",
    "    publicRatings = utility_matrix_train_nan.mean().values\n",
    "    values = utility_matrix_train.values\n",
    "    means = np.true_divide(values.sum(1),(values!=0).sum(1))\n",
    "    for user in range(predictions_simpleavg.shape[0]):\n",
    "        indices = utility_matrix_test.values[user]>0 # Books that were rated by the user in the test set\n",
    "        avgPublicRatings = utility_matrix_train_nan.ix[:,indices].mean().values # avg rating of the public for predict indices\n",
    "        avgPublicRatings[np.isnan(avgPublicRatings)] = avgPublicRatings[avgPublicRatings>0].mean() # impute missing values\n",
    "        avgPublicRatings[np.isnan(avgPublicRatings)] = utility_matrix_train_nan.mean().mean()\n",
    "        avgRating = means[user] # Avg rating for user across all books\n",
    "        if np.isnan(avgRating): # no user ratings available\n",
    "            predictions_simpleavg[user,indices] = avgPublicRatings\n",
    "            #print(user, \"no history\")\n",
    "            continue\n",
    "        predictionsToMake = 0.6*avgRating + 0.4*avgPublicRatings\n",
    "        #predictionsToMake[predictionsToMake>5.0] = 5.0\n",
    "        predictions_simpleavg[user,indices] = predictionsToMake\n",
    "        if np.isnan(predictions_simpleavg[user,:]).sum()>0: print user, \"NANS FOUND\", avgPublicRatings[avgPublicRatings>0].mean(); break\n",
    "        if user%100==0: print user, \" users completed\"    \n",
    "\n",
    "    return predictions_simpleavg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  users completed\n",
      "100  users completed\n",
      "300  users completed\n",
      "400  users completed\n",
      "500  users completed\n",
      "600  users completed\n",
      "700  users completed\n",
      "800  users completed\n"
     ]
    }
   ],
   "source": [
    "predictions_simpleAvg = predictSimpleAvg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that no predictions are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(predictions_simpleAvg[1]).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4290\n",
      "4290\n"
     ]
    }
   ],
   "source": [
    "print(predictions>0).sum()\n",
    "print(utility_matrix_test.values>0).sum()\n",
    "predictions_combined_all = 0.25*(predictions_all[0]+predictions_all[1]+predictions+predictions_simpleAvg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get RMSE for all methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "indices_where_history = utility_matrix_train.values.sum(1)>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Review Similarity\n",
      "0.733816859168\n",
      "Ratings Similarity\n",
      "0.74412184859\n",
      "Combined Text and Ratings Similarity\n",
      "0.731598498086\n",
      "Simple Average\n",
      "0.736580015436\n",
      "Combined Text, Ratings, and Similarity\n",
      "0.724892176394\n"
     ]
    }
   ],
   "source": [
    "all_models = [predictions_all[0], predictions_all[1], predictions, predictions_simpleAvg,predictions_combined_all]\n",
    "model_names = [\"Text Review Similarity\", \"Ratings Similarity\", \"Combined Text and Ratings Similarity\",\"Simple Average\", \"Combined Text, Ratings, and Similarity\"]\n",
    "test_matrix_history_only = utility_matrix_test.values[indices_where_history,:]\n",
    "for model in range(5):\n",
    "    print model_names[model]\n",
    "    squared_error = (all_models[model][indices_where_history,:]-test_matrix_history_only)**2 # just the squared error\n",
    "    #sq_error_only_rated_books = squared_error*(utility_matrix_test.values>0) # make error 0 for non-rated items\n",
    "    mse = np.sum(squared_error)/(test_matrix_history_only>0).sum().sum() # average over non-zero ratings\n",
    "    rmse = mse**0.5 # take square root\n",
    "    print rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot a histogram of residuals for combined text and ratings similarity methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "error = abs(predictions-utility_matrix_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_simple = predictions[predictions>0][0:1000]\n",
    "actual_simple = utility_matrix_test.values[utility_matrix_test.values>0][0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEPCAYAAABY9lNGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117fafb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = abs(predictions_simple - actual_simple)\n",
    "# the histogram of the data\n",
    "n, bins, patches = plt.hist(x, 20, normed=1, facecolor='green', alpha=0.75)\n",
    "\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('Counts')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
